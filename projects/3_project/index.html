<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Machine Learning and Deep Learning Approach To Information Retrieval (2) | Nima Nilchian </title> <meta name="author" content="Nima Nilchian"> <meta name="description" content="Second project of the Modern Information Retrieval course"> <meta name="keywords" content="Nima Nilchian, Webpage, CV, NLP"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nima-nilchian.github.io/projects/3_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Nima</span> Nilchian </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Machine Learning and Deep Learning Approach To Information Retrieval (2)</h1> <p class="post-description">Second project of the Modern Information Retrieval course</p> </header> <article> <p>This project aims to practise Retrieval systems based on machine learning using classification and clustering.</p> <h3 id="1---eda-of-dataset">1 - EDA of dataset:</h3> <p>we start with first Preprocessing document, normalizing, removing stopwords, removing multi-label documents and splitting the document to train and test.</p> <h3 id="2---naive-bayes-classifier">2 - Naive Bayes Classifier</h3> <p>In this project, I developed a document classification system using the Naive Bayes algorithm from scratch, focusing on categorizing documents into one of three predefined classes. The process began with feature extraction, where I created word count vectors for each document, transforming textual data into a numerical format that the classifier could process. I implemented the Naive Bayes classifier from scratch, starting with the calculation of prior probabilities for each class based on their frequency in the dataset. I then estimated the likelihood of each word in the vocabulary occurring within documents from each class, using these likelihoods to inform the classification process. The classifier combined these likelihoods with the prior probabilities to compute the posterior probabilities for each class given a document, ultimately assigning the document to the class with the highest posterior probability. To ensure comprehensive coverage, I selected a balanced subset of the dataset that included documents from all three classes.</p> <p>In the evaluation phase of the trained Naive Bayes model, I assessed its performance using several key metrics: precision, recall, F1 score in both macro and micro settings, and overall accuracy.</p> <p>Furthermore, I generated the ROC curve for this non-binary classification task, extending the typical binary ROC analysis to handle multiple classes.</p> <p>For a more visual analysis, I also constructed the confusion matrix, which shows the count of correct and incorrect predictions per class, without using sklearn and computed manually and visualized the results using matplotlib and seaborn.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/roc-480.webp 480w,/assets/img/projects/roc-800.webp 800w,/assets/img/projects/roc-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/roc.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">The ROC-Curve (Orange: class0, Green: class1, Blue: class2)</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/confusion-480.webp 480w,/assets/img/projects/confusion-800.webp 800w,/assets/img/projects/confusion-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/confusion.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">The Confusion Matrix</div> </div> </div> <h3 id="3---classification-with-neural-networks">3 - Classification with Neural Networks:</h3> <p>In this task, I built a <strong>neural network</strong> to classify scientific articles based on their <strong>abstracts</strong> and <strong>titles</strong>. I used <strong>FastText</strong> to generate <strong>100-dimensional embeddings</strong> for each word in the articles. These embeddings were then averaged using <strong>TF-IDF</strong> weights to create a final vector representation for each article. The neural network was trained on these embeddings, with the <strong>labels</strong> converted into numerical form. I monitored the model’s performance using <strong>training</strong> and <strong>validation losses</strong>, ensuring accurate prediction of article topics. The loss is visualized through learning curves, providing insights into how the model was learning over time.</p> <div class="row justify-content-center"> <div class="col-sm-8 col-md-6 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/loss_curv-480.webp 480w,/assets/img/projects/loss_curv-800.webp 800w,/assets/img/projects/loss_curv-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/loss_curv.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">The Loss Curve</div> </div> </div> <p>The neural network model was evaluated using several metrics to assess its accuracy and effectiveness in classifying scientific articles. Below is a summary of the evaluation results:</p> <table> <thead> <tr> <th><strong>Metric</strong></th> <th><strong>Value</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Accuracy</strong></td> <td>0.9522</td> </tr> <tr> <td><strong>Test Loss</strong></td> <td>0.0201</td> </tr> <tr> <td><strong>F1 Score (Macro)</strong></td> <td>0.9521</td> </tr> <tr> <td><strong>F1 Score (Micro)</strong></td> <td>0.9522</td> </tr> <tr> <td><strong>Precision (Macro)</strong></td> <td>0.9522</td> </tr> <tr> <td><strong>Recall (Macro)</strong></td> <td>0.9527</td> </tr> <tr> <td><strong>Precision (Micro)</strong></td> <td>0.9522</td> </tr> <tr> <td><strong>Recall (Micro)</strong></td> <td>0.9522</td> </tr> </tbody> </table> <p><br></p> <h3 id="4---classification-with-language-models">4 - Classification with Language Models:</h3> <p>In this task, we built a <strong>classification model</strong> using the well-known <strong>BERT</strong> model from the <strong>Transformers</strong> library.</p> <h6 id="steps-involved"><strong>Steps Involved:</strong></h6> <ol> <li> <p><strong>Loading the Model and Tokenizer:</strong><br> We began by loading the pre-trained <strong>BERT</strong> model and its corresponding <strong>tokenizer</strong> using the <strong>Transformers</strong> library to preprocess the text data.</p> </li> <li> <p><strong>Fine-Tuning the Model:</strong><br> Using the dataset from previous tasks, we performed <strong>fine-tuning</strong> on the BERT model. The <strong>Trainer</strong> API from the <strong>Transformers</strong> library facilitated this process, providing a streamlined interface for training and evaluation.</p> </li> <li> <p><strong>Freezing Model Weights:</strong><br> In one experiment, we <strong>froze the weights</strong> of the BERT model and only trained the <strong>classification head</strong>. This approach allowed us to evaluate the impact of updating the pre-trained weights on model performance.</p> </li> <li> <p><strong>Evaluating :</strong><br> We then evaluated both models using the test dataset. Based on the outputs, we computed relevant performance metrics to assess the effectiveness of each model.</p> </li> </ol> <p>Here is the evaluation statistics of the two models using the test dataset, presented in table format:</p> <table> <thead> <tr> <th><strong>Metric</strong></th> <th><strong>Model 1</strong></th> <th><strong>Model 2</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Accuracy</strong></td> <td>0.8755</td> <td>0.6675</td> </tr> <tr> <td><strong>F1-Macro</strong></td> <td>0.6021</td> <td>0.4458</td> </tr> <tr> <td><strong>F1-Micro</strong></td> <td>0.8755</td> <td>0.6675</td> </tr> <tr> <td><strong>Precision (Macro)</strong></td> <td>0.7464</td> <td>0.4399</td> </tr> <tr> <td><strong>Recall (Macro)</strong></td> <td>0.6164</td> <td>0.4574</td> </tr> <tr> <td><strong>Precision (Micro)</strong></td> <td>0.8755</td> <td>0.6675</td> </tr> <tr> <td><strong>Recall (Micro)</strong></td> <td>0.8755</td> <td>0.6675</td> </tr> </tbody> </table> <p><br></p> <h3 id="5---clustering-the-documents">5 - Clustering the documents:</h3> <p>In this task, we focused on <strong>document clustering</strong> using <strong>embedding vectors</strong> and various clustering algorithms.</p> <h4 id="steps-involved-1">Steps Involved:</h4> <ol> <li> <p><strong>Extracting Document Embeddings:</strong><br> Instead of using basic methods like Bag of Words, we utilized <strong>transformer-based language models</strong> to generate high-quality embeddings for each document. We implemented the <code class="language-plaintext highlighter-rouge">extract_embedding</code> function to take a list of documents as input and return a list of corresponding embedding vectors. Techniques such as using the CLS token embedding from BERT or averaging word embeddings (weighted or unweighted) were employed.</p> </li> <li> <p><strong>Dimensionality Reduction for Visualization:</strong><br> To visualize the clustering results, we reduced the dimensionality of the embedding vectors to two dimensions using <strong>T-SNE</strong>. We implemented the <code class="language-plaintext highlighter-rouge">convert_to_2d_tsne</code> function to convert high-dimensional embeddings into 2D vectors for plotting. Note that dimensionality reduction is only used for visualization purposes; all clustering steps are performed on the original, high-dimensional vectors.</p> </li> <li> <p><strong>Clustering with KMeans and Hierarchical Clustering:</strong><br> We used <strong>KMeans</strong> and <strong>Hierarchical Clustering</strong> algorithms to create clusters from the embedding vectors. These clustering techniques help group similar documents based on their embeddings.</p> </li> <li> <p><strong>Plotting the Clusters:</strong><br> We implemented the <code class="language-plaintext highlighter-rouge">plot_docs</code> function to visualize the clustering results. This function takes 2D reduced vectors and cluster assignments as input and generates a 2D scatter plot where each point represents a document, colored according to its cluster. This visualization helps in understanding the distribution and separation of clusters.</p> </li> </ol> <div class="row justify-content-center"> <div class="col-sm-8 col-md-6 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/tsne-480.webp 480w,/assets/img/projects/tsne-800.webp 800w,/assets/img/projects/tsne-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/tsne.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Dimentionality Reduction using T-SNE</div> </div> </div> <h4 id="k-means"><strong>K-Means:</strong></h4> <p>In the <strong>K-means clustering</strong> project, you will implement the K-means algorithm from scratch to group documents into clusters based on their embeddings. First, you will create the algorithm to compute cluster centroids and assign each document to the nearest centroid for various values of <strong>k</strong> (the number of clusters). Next, you’ll analyze the clustering results by determining the topics of each cluster using representative documents. You will also conduct a <strong><code class="language-plaintext highlighter-rouge">silhouette analysis</code></strong> to evaluate the quality of the clusters by plotting the silhouette score for different k values, helping you select the optimal k. Additionally, you will calculate and visualize the <strong><code class="language-plaintext highlighter-rouge">purity</code></strong> of the clusters using labeled data to assess the effectiveness of your clustering. Finally, all steps will be encapsulated in a function, <strong><code class="language-plaintext highlighter-rouge">cluster_kmeans</code></strong>, which takes embedding vectors as input and outputs the cluster centroids and assignments.</p> <p>Clustering Results for K Values from 2 to 7:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/means2-480.webp 480w,/assets/img/projects/means2-800.webp 800w,/assets/img/projects/means2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/means2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/means3-480.webp 480w,/assets/img/projects/means3-800.webp 800w,/assets/img/projects/means3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/means3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/means4-480.webp 480w,/assets/img/projects/means4-800.webp 800w,/assets/img/projects/means4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/means4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/means5-480.webp 480w,/assets/img/projects/means5-800.webp 800w,/assets/img/projects/means5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/means5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/means6-480.webp 480w,/assets/img/projects/means6-800.webp 800w,/assets/img/projects/means6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/means6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/means7-480.webp 480w,/assets/img/projects/means7-800.webp 800w,/assets/img/projects/means7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/means7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Visual representation of document clusters using K-means with varying values of K, highlighting how clusters change as K increases. </div> <p>Silhouette Analysis for Cluster Quality and Purity Scores of Document Clusters:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/silhouette-480.webp 480w,/assets/img/projects/silhouette-800.webp 800w,/assets/img/projects/silhouette-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/silhouette.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">A silhouette plot showing the silhouette scores for different values of K</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/purity-480.webp 480w,/assets/img/projects/purity-800.webp 800w,/assets/img/projects/purity-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/purity.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Visualization of purity scores for various K values</div> </div> </div> <h4 id="hierarchical-clustering-method"><strong>Hierarchical Clustering Method:</strong></h4> <p>Hierarchical clustering is a technique used in machine learning for grouping data into a tree-like structure of clusters. In this task, you will utilize libraries such as SciPy or other Python libraries to perform hierarchical clustering on your dataset. After applying the clustering algorithm, you will visualize the resulting clusters using Matplotlib, allowing you to see the relationships and structure among the data points based on their similarities.</p> <div class="row justify-content-center"> <div class="col-sm col-md mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/hierarchical-480.webp 480w,/assets/img/projects/hierarchical-800.webp 800w,/assets/img/projects/hierarchical-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/hierarchical.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">the hierarchical clustering of data, showcasing the tree-like structure of clusters and their relationships</div> </div> </div> <p>In conclusion, this project comprehensively explored various methods for analyzing and classifying scientific documents, beginning with an <strong>Exploratory Data Analysis (EDA)</strong> to understand the dataset’s structure and characteristics. The <strong>Naive Bayes Classifier</strong> was implemented as a baseline model, followed by advanced <strong>classification techniques using Neural Networks</strong> and <strong>language models</strong>. While the use of language models like BERT was intended to enhance classification performance, it resulted in decreased F1 scores due to insufficient data and the complexity of the models, which negatively affected the classification performance. Subsequently, we employed <strong>clustering techniques</strong> such as <strong>K-means</strong> and <strong>Hierarchical Clustering</strong> to group similar documents, utilizing dimensionality reduction for effective visualization of the clusters enhancing our understanding of the document relationships and classifications.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Nima Nilchian. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-binary-stress-detection",title:"Binary Stress Detection",description:"Fine-tuned, evaluated and compared LLMs for binary stress detection and stress category classification. [Github](https://github.com/Nima-Nilchian/stress-detection)",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-web-information-retrieval-3",title:"Web Information Retrieval (3)",description:"third project of the Modern Information Retrieval course",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-machine-learning-and-deep-learning-approach-to-information-retrieval-2",title:"Machine Learning and Deep Learning Approach To Information Retrieval (2)",description:"Second project of the Modern Information Retrieval course",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-traditional-information-retrieval-1",title:"Traditional Information Retrieval (1)",description:"Second project of the Modern Information Retrieval course",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6E%69%6D%61.%6E%69%6C%63%68%69%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Nima-Nilchian","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/nima-nilchian","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/nima_nlc","_blank")}},{id:"socials-instagram",title:"Instagram",section:"Socials",handler:()=>{window.open("https://instagram.com/nima_nilchian","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>